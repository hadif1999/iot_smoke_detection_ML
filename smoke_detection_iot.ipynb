{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hadif1999/iot_smoke_detection_ML/blob/main/smoke_detection_iot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62agNjnzyefX"
   },
   "source": [
    "#smoke_detection_iot project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGSbyun11hBp"
   },
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rYh_aMG1hBq"
   },
   "source": [
    "In this section, data are loaded, inspected, and cleaned. Correlation is checked, outliers are removed, and missing values are verified before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COoVpHH1RB8j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as tfk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80lTfRfI1hBs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1f4c350",
    "outputId": "682f6b87-6079-4ceb-9991-3593c77dff7a"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with the actual raw GitHub URL of your CSV file\n",
    "github_csv_url = \"https://raw.githubusercontent.com/hadif1999/iot_smoke_detection_ML/main/smoke_detection_iot.csv\"\n",
    "\n",
    "response = requests.get(github_csv_url)\n",
    "response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "with open(\"smoke_detection_iot.csv\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Dataset downloaded successfully to smoke_detection_iot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "1uzfX4ORReUL",
    "outputId": "5e6e7fcc-9482-41ff-8ec0-8426821aaf1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"smoke_detection_iot.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0Wdenf-Yq1H"
   },
   "source": [
    "Columns explanation :\n",
    "<br>\n",
    "Air Temperature\n",
    "<br>\n",
    "Air Humidity\n",
    "<br>\n",
    "\n",
    "TVOC: Total Volatile Organic Compounds; measured in parts per billion (Source)\n",
    "<br>\n",
    "eCO2: co2 equivalent concentration; calculated from different values like TVCO\n",
    "<br>\n",
    "Raw H2: raw molecular hydrogen; not compensated (Bias, temperature, etc.)\n",
    "<br>\n",
    "Raw Ethanol: raw ethanol gas (Source)¶\n",
    "<br>\n",
    "PM 1.0 and PM 2.5: particulate matter size < 1.0 µm (PM1.0). 1.0 µm < 2.5 µm (PM2.5)\n",
    "<br>\n",
    "Fire Alarm: ground truth is \"1\" if a fire is there\n",
    "<br>\n",
    "CNT: Sample counter\n",
    "<br>\n",
    "UTC: Timestamp UTC seconds\n",
    "<br>\n",
    "NC0.5/NC1.0 and NC2.5: Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air.\n",
    "<br>\n",
    "The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "eSFP6OdGZdyt",
    "outputId": "2bbf1c4b-9e8c-4fc6-add3-9ce92d968df1"
   },
   "outputs": [],
   "source": [
    "data.corr()[\"Fire Alarm\"].sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6NNdZXgYpyH"
   },
   "outputs": [],
   "source": [
    "cols = ['Unnamed: 0',\"PM2.5\" , 'CNT' ,\n",
    "             'UTC' , \"Raw H2\",\n",
    "       'PM1.0' , 'NC0.5' ,'NC1.0' ,'NC2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ZP5JkE8ElPUT",
    "outputId": "aff88896-a2fb-40de-f67a-f9c7ea399f02"
   },
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "data2.drop(cols, axis=1, inplace=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "jdgqhOT9Z_xD",
    "outputId": "6927bcc7-bce5-42ce-e932-b74081808f9d"
   },
   "outputs": [],
   "source": [
    "data2.plot(kind='box', subplots=True, layout=(8,5), figsize=(17,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEvV2TiP8FCp"
   },
   "outputs": [],
   "source": [
    "def outlier_bands(df, multiplier: int = 1.5):\n",
    "\n",
    " Q1 = df.quantile(0.25)\n",
    " Q3 = df.quantile(0.75)\n",
    "\n",
    " IQR = Q3-Q1\n",
    " lower_band = Q1 - multiplier*IQR\n",
    " upper_band = Q3 + multiplier*IQR\n",
    "\n",
    "\n",
    " return lower_band,upper_band\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVl2GmPMGu4H",
    "outputId": "a8a686a9-2040-4eee-a69f-fd2fd601e555"
   },
   "outputs": [],
   "source": [
    "low_band, up_band = outlier_bands(data2, multiplier=2)\n",
    "\n",
    "data_clean = data2.copy()\n",
    "\n",
    "# Create a boolean mask to identify rows with outliers\n",
    "# A row is an outlier if any of its values are either greater than the upper band\n",
    "# or less than the lower band for the respective column.\n",
    "outlier_mask = ((data_clean > up_band) | (data_clean < low_band)).any(axis=1)\n",
    "\n",
    "# Filter out the outlier rows\n",
    "data_clean = data_clean[~outlier_mask]\n",
    "\n",
    "print(f\"Removed {len(data2) - len(data_clean)} outlier rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKSkUfG-1hBv"
   },
   "source": [
    "**Note on Outlier Removal**\n",
    "Outliers are removed using bounds computed on the full dataset. This can introduce leakage in strict evaluation, but it is retained here to preserve consistency with the current results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9D9oEDoIbelb",
    "outputId": "c908efe2-bbb4-445e-cab2-a8430080c4ae"
   },
   "outputs": [],
   "source": [
    "data_clean.shape, data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "up2GEjpFeIz-",
    "outputId": "82a04237-2a4f-4683-97cb-b0ab83eb5a41"
   },
   "outputs": [],
   "source": [
    "data_clean = data_clean.reset_index(drop = True)\n",
    "#data_clean.drop([\"level_0\",\"index\"],axis=1,inplace=True)\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ytx_wINChqEy",
    "outputId": "73847f1c-307d-4ee0-968f-6697b6367861"
   },
   "outputs": [],
   "source": [
    "data_clean.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaiwfkstligM"
   },
   "outputs": [],
   "source": [
    "y = data_clean[\"Fire Alarm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70euNKB_oOWE",
    "outputId": "c3ead83b-27ca-4486-b5dc-2bff5c406271"
   },
   "outputs": [],
   "source": [
    "y = y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "ps7hJn7J1hBw",
    "outputId": "30a44bc4-1c87-4cb8-cf56-320cf647713d"
   },
   "outputs": [],
   "source": [
    "# Data profiling: missing values and class balance\n",
    "missing_summary = data_clean.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Class balance (Fire Alarm):\")\n",
    "class_counts = data_clean[\"Fire Alarm\"].value_counts().sort_index()\n",
    "class_perc = (class_counts / class_counts.sum() * 100).round(2)\n",
    "class_balance = pd.DataFrame({\"Count\": class_counts, \"Percent\": class_perc})\n",
    "class_balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7yccSKto4Gu"
   },
   "outputs": [],
   "source": [
    "x = data_clean[[\"Temperature[C]\",\"Humidity[%]\",\"TVOC[ppb]\",\"eCO2[ppm]\",\"Raw Ethanol\",\"Pressure[hPa]\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmiwv5q31hBw"
   },
   "outputs": [],
   "source": [
    "feature_names = [\"Temperature[C]\", \"Humidity[%]\", \"TVOC[ppb]\", \"eCO2[ppm]\", \"Raw Ethanol\", \"Pressure[hPa]\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gndXXvWP1hBw"
   },
   "source": [
    "# Neural Network (MLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oVwNFzy1hBw"
   },
   "source": [
    "A simple feed-forward neural network is trained and evaluated first with a holdout split, then with K-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaDNGMzX1hBw"
   },
   "source": [
    "## Holdout Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZ53bHVNvzz2"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNZqMOsPwth4"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.15, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvvn0Ef2U_s3"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UN9rqZ-yx5B"
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_gen ( n_HD_layer , n_neuron_list , input_shape = data_clean.shape[1:], ac_f = \"sigmoid\"):\n",
    "\n",
    "  if not n_HD_layer == len(n_neuron_list) : print(\"number of hidden layers must be equal to len of list of number of neurons in each layer \")\n",
    "\n",
    "  layer_list = []\n",
    "\n",
    "  input_layer = tfk.layers.Input(input_shape,name = \"input_layer\")\n",
    "  layer_list.append(input_layer)\n",
    "\n",
    "  for i in range(n_HD_layer):\n",
    "\n",
    "    hd_layer = tfk.layers.Dense(n_neuron_list[i], ac_f ,False,\"glorot_normal\",name = \"hd_layer{}\".format(i+1))(layer_list[-1])\n",
    "    batch_layer = tfk.layers.BatchNormalization(name = \"batch_layer{}\".format(i+1))(hd_layer)\n",
    "    drop_layer = tfk.layers.Dropout( 0.4 ,name = \"drop_layer{}\".format(i+1) )(batch_layer)\n",
    "\n",
    "    layer_list.append(hd_layer)\n",
    "    layer_list.append(batch_layer)\n",
    "    layer_list.append(drop_layer)\n",
    "\n",
    "  #drop_layer_final = tfk.layers.Dropout(0.4)(layer_list[-1])\n",
    "  #layer_list.append(drop_layer_final)\n",
    "\n",
    "  out_layer = tfk.layers.Dense(1,\"sigmoid\",False,name = \"output_layer\")(layer_list[-1])\n",
    "\n",
    "  model = tfk.Model(inputs=input_layer , outputs =out_layer,name = \"model01\" )\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ywKoEBVW8EVG",
    "outputId": "47e4e24d-40b0-46ea-c8eb-d52fe577b982"
   },
   "outputs": [],
   "source": [
    "model_args = dict(n_HD_layer=2 , n_neuron_list=[40, 20])\n",
    "\n",
    "model1 = model_gen(**model_args, input_shape = X_train.shape[1:])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1HGTgHO8bG1"
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer = \"Adam\", loss=\"binary_crossentropy\",\n",
    "               metrics = [\"accuracy\",\"binary_accuracy\",\n",
    "                          tfk.metrics.AUC(),tfk.metrics.Precision(),tfk.metrics.Recall()],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VQAeI8YtWOh",
    "outputId": "ec95222d-be70-447a-d1c7-5e9086214c99"
   },
   "outputs": [],
   "source": [
    "hist1 = model1.fit(x = X_train, y = Y_train , batch_size = 24 , epochs = 3, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McIF6I0V1hBx"
   },
   "source": [
    "## Training History Plots\n",
    "Learning curves are plotted to visualize optimization progress (loss/metrics across epochs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IKjsM23N1hBx",
    "outputId": "6baccfce-3a0d-4987-9606-564d4f56d30a"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "history = hist1.history\n",
    "metrics = [m for m in history.keys() if not m.startswith(\"val_\")]\n",
    "\n",
    "cols = 2\n",
    "rows = math.ceil(len(metrics) / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 4 * rows))\n",
    "axes = axes.flatten() if hasattr(axes, \"flatten\") else [axes]\n",
    "\n",
    "for i, m in enumerate(metrics):\n",
    "    axes[i].plot(history[m], label=m)\n",
    "    if f\"val_{m}\" in history:\n",
    "        axes[i].plot(history[f\"val_{m}\"], label=f\"val_{m}\")\n",
    "    axes[i].set_title(m)\n",
    "    axes[i].set_xlabel(\"epoch\")\n",
    "    axes[i].set_ylabel(m)\n",
    "    axes[i].legend()\n",
    "\n",
    "# remove unused axes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCfocFbUt9Ne",
    "outputId": "a4372431-ddd9-486c-91aa-99cc5dab9094"
   },
   "outputs": [],
   "source": [
    "model1.save(\"smoke_detection_iot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EE-a1fVseVeV",
    "outputId": "e16cf30d-bfc0-4f6c-cb2b-d2efddd731cb"
   },
   "outputs": [],
   "source": [
    "eval = model1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USBwsv0vfLXG",
    "outputId": "faed8c41-2a9d-424e-b54b-99b859da77ca"
   },
   "outputs": [],
   "source": [
    "print(\"final accuracy for test data is : \" , eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "id": "UksKaViuf-io",
    "outputId": "c5945c06-f453-46c0-ce18-0e4213e3bac6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_hat = model1.predict(X_test)\n",
    "y_hat_ = np.round(y_hat.T[0])\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_hat_)\n",
    "\n",
    "# Define class labels for clarity\n",
    "class_labels = ['No Alarm', 'Alarm']\n",
    "\n",
    "# Plotting the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(Y_test, y_hat_, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "619nhXui1hB3"
   },
   "source": [
    "## ROC Curve (Neural Network)\n",
    "ROC is computed from the holdout test probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "lg8zOMfM1hB3",
    "outputId": "ca83caf4-8081-4f98-a489-c507e2287a90"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(Y_test, y_hat)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"NN ROC (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Neural Network (Holdout)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh-XkpqM1hB4"
   },
   "source": [
    "## K-Fold Cross-Validation (Neural Network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f208849a"
   },
   "outputs": [],
   "source": [
    "if not isinstance(y, np.ndarray):\n",
    "    y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61704df1",
    "outputId": "10f11432-a87f-453d-9a71-dd318095d670"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"KFold object 'kf' initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed00c778",
    "outputId": "318f2a7e-37ce-4b5c-e8ad-99b138ccbae0"
   },
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "loss_scores = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(x)):\n",
    "    print(f\"\\n--- Fold {fold+1}/{kf.n_splits} ---\")\n",
    "    # 3. Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = x[train_index], x[val_index]\n",
    "    Y_train_fold, Y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # 4 & 5. Instantiate StandardScaler and apply it\n",
    "    sc = StandardScaler()\n",
    "    X_train_fold = sc.fit_transform(X_train_fold)\n",
    "    X_val_fold = sc.transform(X_val_fold)\n",
    "\n",
    "    # 6. Create a new model instance for the current fold\n",
    "    model_fold = model_gen(**model_args, input_shape=X_train_fold.shape[1:])\n",
    "\n",
    "    # 7. Compile the new model\n",
    "    model_fold.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\",\n",
    "                       metrics=[\"accuracy\", \"binary_accuracy\",\n",
    "                                  tfk.metrics.AUC(), tfk.metrics.Precision(), tfk.metrics.Recall()])\n",
    "\n",
    "    # 8. Train the model\n",
    "    history = model_fold.fit(x=X_train_fold, y=Y_train_fold, batch_size=24, epochs=3, verbose=1) # Set verbose to 0 to suppress output for each epoch\n",
    "\n",
    "    # 9. Evaluate the trained model\n",
    "    eval_metrics = model_fold.evaluate(X_val_fold, Y_val_fold, verbose=0)\n",
    "    print(f\"Fold {fold+1} Evaluation: Loss = {eval_metrics[0]:.4f}, Accuracy = {eval_metrics[1]:.4f}, AUC = {eval_metrics[3]:.4f}, Precision = {eval_metrics[4]:.4f}, Recall = {eval_metrics[5]:.4f}\")\n",
    "\n",
    "    # 10. Append the evaluated metrics to their respective lists\n",
    "    loss_scores.append(eval_metrics[0])\n",
    "    accuracy_scores.append(eval_metrics[1])\n",
    "    auc_scores.append(eval_metrics[3]) # Assuming AUC is at index 3 based on compile metrics\n",
    "    precision_scores.append(eval_metrics[4])\n",
    "    recall_scores.append(eval_metrics[5]) # Assuming Recall is at index 5 based on compile metrics\n",
    "\n",
    "print(\"\\nK-fold cross-validation complete. Metrics stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzB4612r1hB4",
    "outputId": "19258ee9-d63a-47d7-87f6-de494e134320"
   },
   "outputs": [],
   "source": [
    "print(\"Average Accuracy: {:.4f} (+/- {:.4f})\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"Average AUC: {:.4f} (+/- {:.4f})\".format(np.mean(auc_scores), np.std(auc_scores)))\n",
    "print(\"Average Precision: {:.4f} (+/- {:.4f})\".format(np.mean(precision_scores), np.std(precision_scores)))\n",
    "print(\"Average Recall: {:.4f} (+/- {:.4f})\".format(np.mean(recall_scores), np.std(recall_scores)))\n",
    "print(\"Average Loss: {:.4f} (+/- {:.4f})\".format(np.mean(loss_scores), np.std(loss_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLm4Esla1hB4"
   },
   "source": [
    "# Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr01mKwz1hB4"
   },
   "source": [
    "The same K-fold protocol is applied to a classical SVM baseline for comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr4MGDHt1hB4"
   },
   "source": [
    "## K-Fold Cross-Validation (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e00a1ef8",
    "outputId": "a60fac93-baa3-48e1-f5a9-b11b711cea42"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_accuracy_scores = []\n",
    "svm_precision_scores = []\n",
    "svm_recall_scores = []\n",
    "svm_f1_scores = []\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred_svm = []\n",
    "all_y_score_svm = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(x)):\n",
    "    print(f\"\\n--- SVM Fold {fold+1}/{kf.n_splits} ---\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = x[train_index], x[val_index]\n",
    "    Y_train_fold, Y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Scale the data\n",
    "    sc_svm = StandardScaler()\n",
    "    X_train_fold_scaled = sc_svm.fit_transform(X_train_fold)\n",
    "    X_val_fold_scaled = sc_svm.transform(X_val_fold)\n",
    "\n",
    "    # Instantiate a new SVC classifier\n",
    "    svm_model_fold = SVC(random_state=42, C=0.5)\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm_model_fold.fit(X_train_fold_scaled, Y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_svm_fold = svm_model_fold.predict(X_val_fold_scaled)\n",
    "\n",
    "    # Decision scores for ROC\n",
    "    y_score_svm_fold = svm_model_fold.decision_function(X_val_fold_scaled)\n",
    "\n",
    "    # Calculate metrics for the current fold\n",
    "    report = classification_report(Y_val_fold, y_pred_svm_fold, output_dict=True)\n",
    "\n",
    "    # Extract metrics for the positive class (class 1)\n",
    "    accuracy_fold = report['accuracy']\n",
    "    precision_fold = report['1']['precision']\n",
    "    recall_fold = report['1']['recall']\n",
    "    f1_fold = report['1']['f1-score']\n",
    "\n",
    "    print(f\"Fold {fold+1} Accuracy: {accuracy_fold:.4f}\")\n",
    "    print(f\"Fold {fold+1} Precision (Class 1): {precision_fold:.4f}\")\n",
    "    print(f\"Fold {fold+1} Recall (Class 1): {recall_fold:.4f}\")\n",
    "    print(f\"Fold {fold+1} F1-Score (Class 1): {f1_fold:.4f}\")\n",
    "\n",
    "    # Append metrics to lists\n",
    "    svm_accuracy_scores.append(accuracy_fold)\n",
    "    svm_precision_scores.append(precision_fold)\n",
    "    svm_recall_scores.append(recall_fold)\n",
    "    svm_f1_scores.append(f1_fold)\n",
    "\n",
    "    # Accumulate true and predicted labels\n",
    "    all_y_true.extend(Y_val_fold)\n",
    "    all_y_pred_svm.extend(y_pred_svm_fold)\n",
    "    all_y_score_svm.extend(y_score_svm_fold)\n",
    "\n",
    "print(\"\\nSVM K-fold cross-validation complete. Metrics and predictions stored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJ2P5BRH1hB5"
   },
   "source": [
    "## SVM Evaluation Summary\n",
    "A consolidated set of metrics is computed from all folds to summarize SVM performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w87Y0zHU1hB5",
    "outputId": "000a0ddd-a2fc-4f09-ecf9-a0cf674465d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "svm_accuracy = accuracy_score(all_y_true, all_y_pred_svm)\n",
    "svm_precision = precision_score(all_y_true, all_y_pred_svm)\n",
    "svm_recall = recall_score(all_y_true, all_y_pred_svm)\n",
    "svm_f1 = f1_score(all_y_true, all_y_pred_svm)\n",
    "\n",
    "print(f\"SVM Accuracy:  {svm_accuracy:.4f}\")\n",
    "print(f\"SVM Precision: {svm_precision:.4f}\")\n",
    "print(f\"SVM Recall:    {svm_recall:.4f}\")\n",
    "print(f\"SVM F1-Score:  {svm_f1:.4f}\")\n",
    "\n",
    "# store for comparison table\n",
    "svm_summary = {\n",
    "    \"Accuracy\": svm_accuracy,\n",
    "    \"Precision\": svm_precision,\n",
    "    \"Recall\": svm_recall,\n",
    "    \"F1\": svm_f1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WFLN3Us1hB5"
   },
   "source": [
    "## Metrics and Confusion Matrix for SVM\n",
    "A consolidated classification report and confusion matrix are produced from all folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "id": "hvUzvZf51hB5",
    "outputId": "857bf759-0d6c-4a78-e56b-e5bb6a59235b"
   },
   "outputs": [],
   "source": [
    "print(\"Consolidated Classification Report for SVM (K-fold):\")\n",
    "print(classification_report(all_y_true, all_y_pred_svm, target_names=['No Alarm', 'Alarm']))\n",
    "\n",
    "# Generate the consolidated confusion matrix\n",
    "cm_svm_consolidated = confusion_matrix(all_y_true, all_y_pred_svm)\n",
    "\n",
    "# Plotting the consolidated confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm_consolidated, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No Alarm', 'Alarm'], yticklabels=['No Alarm', 'Alarm'])\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Consolidated Confusion Matrix for SVM (K-fold)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Consolidated Confusion Matrix (K-fold):\\n\", cm_svm_consolidated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUAmc2bU1hB5"
   },
   "source": [
    "## ROC Curve (SVM)\n",
    "ROC is computed from consolidated decision scores across folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "mxGe-tDc1hB5",
    "outputId": "3dfb5cec-0d87-4250-a878-8fa86e0bdadb"
   },
   "outputs": [],
   "source": [
    "fpr_svm, tpr_svm, _ = roc_curve(all_y_true, all_y_score_svm)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_svm, tpr_svm, label=f\"SVM ROC (AUC = {roc_auc_svm:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM (K-Fold Consolidated)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9DbBcKE1hB5"
   },
   "source": [
    "## SHAP Value Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485,
     "referenced_widgets": [
      "b6dd7ec8139648598ff619cf1f3ff6d6",
      "03e334115a4d468ba8b25bfc890c57d2",
      "234f7feb7e6043c0baa78c9c2c9116c2",
      "0a1aa4b1538a48559a2c96e98f38eed5",
      "ced00cc34a94477eb50059a73fa5b315",
      "4247cfe5cf5948dd8102b88cda0dddd0",
      "e04695933e9f4cfdb6424dcd28e064fc",
      "d806b0afc2a944b9af538875c72b7e98",
      "a92a5441787b4136b0d4ac49d0245fc8",
      "5220e60c8bb041609c209e6e26d9d67d",
      "2581111a76a94fcaa8192d672db1ebf1"
     ]
    },
    "id": "MjiK_I4B1hB5",
    "outputId": "ecb81d79-42ab-40a1-a942-1fe1ba001318"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "except ImportError:\n",
    "    print(\"SHAP is not installed. run pip install shap\")\n",
    "else:\n",
    "    # Train a full SVM model for interpretability\n",
    "    sc_full = StandardScaler()\n",
    "    X_full_scaled = sc_full.fit_transform(x)\n",
    "\n",
    "    svm_full = SVC(random_state=42, C=0.5, probability=True)\n",
    "    svm_full.fit(X_full_scaled, y)\n",
    "\n",
    "    # Sample data for faster SHAP computation\n",
    "    sample_size = min(200, len(X_full_scaled))\n",
    "    background_size = min(100, len(X_full_scaled))\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "    sample_idx = rng.choice(len(X_full_scaled), size=sample_size, replace=False)\n",
    "    background_idx = rng.choice(len(X_full_scaled), size=background_size, replace=False)\n",
    "\n",
    "    X_sample = X_full_scaled[sample_idx]\n",
    "    background = X_full_scaled[background_idx]\n",
    "\n",
    "    # Wrap predict_proba to return only the probability of the positive class (index 1)\n",
    "    # This ensures explainer.shap_values returns a 2D array, which summary_plot expects directly.\n",
    "    def model_predict_proba_wrapper(x_input):\n",
    "        return svm_full.predict_proba(x_input)[:, 1]\n",
    "\n",
    "    explainer = shap.KernelExplainer(model_predict_proba_wrapper, background)\n",
    "    shap_values = explainer.shap_values(X_sample, nsamples=100) # This will now be (num_samples, num_features)\n",
    "\n",
    "    # Plot SHAP summary (shap_values is now directly for the positive class)\n",
    "    shap.summary_plot(shap_values, X_sample, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCHpooU21hB5"
   },
   "source": [
    "## Comparison Table\n",
    "A small summary table is generated to compare the neural network and SVM using the stored cross-validation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Z0Gn99QN1hB5",
    "outputId": "7abe1edb-8ec6-465a-836e-b22bef085592"
   },
   "outputs": [],
   "source": [
    "# Neural network (K-fold) summary\n",
    "nn_precision = float(np.mean(precision_scores))\n",
    "nn_recall = float(np.mean(recall_scores))\n",
    "nn_f1 = (2 * nn_precision * nn_recall / (nn_precision + nn_recall)) if (nn_precision + nn_recall) > 0 else np.nan\n",
    "\n",
    "nn_summary = {\n",
    "    \"Accuracy\": float(np.mean(accuracy_scores)),\n",
    "    \"Precision\": nn_precision,\n",
    "    \"Recall\": nn_recall,\n",
    "    \"AUC\": float(np.mean(auc_scores)),\n",
    "    \"F1\": nn_f1,\n",
    "    \"Loss\": float(np.mean(loss_scores)),\n",
    "}\n",
    "\n",
    "# SVM summary from consolidated predictions\n",
    "# (Assumes svm_summary was created in the SVM evaluation cell)\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\"Model\": \"Neural Network\", **nn_summary},\n",
    "    {\"Model\": \"SVM\", **svm_summary, \"AUC\": np.nan, \"Loss\": np.nan},\n",
    "], columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"AUC\", \"F1\", \"Loss\"])\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakage-Free Evaluation (Strict)\nThis section re-evaluates the models with train-only preprocessing to reduce leakage. Outlier bounds and scaling are fitted on train data and applied to validation/test splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage-Free Data Setup\nFeatures and labels are taken directly from the raw dataset (no correlation-based filtering).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Leakage-free feature setup\n",
    "lf_features = [\"Temperature[C]\", \"Humidity[%]\", \"TVOC[ppb]\", \"eCO2[ppm]\", \"Raw Ethanol\", \"Pressure[hPa]\"]\n",
    "lf_df = data[lf_features + [\"Fire Alarm\"]].copy()\n",
    "\n",
    "# Basic missing-value check\n",
    "print(\"Missing values (leakage-free setup):\")\n",
    "print(lf_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage-Free Outlier Utilities\nOutlier bounds are computed on the training split only and then applied to validation/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lf_outlier_bounds(train_df, features, multiplier=2.0):\n",
    "    q1 = train_df[features].quantile(0.25)\n",
    "    q3 = train_df[features].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - multiplier * iqr\n",
    "    upper = q3 + multiplier * iqr\n",
    "    return lower, upper\n",
    "\n",
    "def lf_filter_outliers(df, features, lower, upper):\n",
    "    mask = ~((df[features] < lower) | (df[features] > upper)).any(axis=1)\n",
    "    return df[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Evaluation (Leakage-Free)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "    lf_train_df, lf_test_df = train_test_split(\n",
    "        lf_df, test_size=0.15, random_state=10, stratify=lf_df[\"Fire Alarm\"]\n",
    "    )\n",
    "\n",
    "    # Compute bounds from train only\n",
    "    lf_lower, lf_upper = lf_outlier_bounds(lf_train_df, lf_features, multiplier=2.0)\n",
    "\n",
    "    # Filter outliers in train and test using train bounds\n",
    "    lf_train_df = lf_filter_outliers(lf_train_df, lf_features, lf_lower, lf_upper)\n",
    "    lf_test_df = lf_filter_outliers(lf_test_df, lf_features, lf_lower, lf_upper)\n",
    "\n",
    "    print(f\"Leakage-free holdout: train={len(lf_train_df)}, test={len(lf_test_df)}\")\n",
    "\n",
    "    X_train_lf = lf_train_df[lf_features].values\n",
    "    y_train_lf = lf_train_df[\"Fire Alarm\"].values\n",
    "    X_test_lf = lf_test_df[lf_features].values\n",
    "    y_test_lf = lf_test_df[\"Fire Alarm\"].values\n",
    "\n",
    "    sc_lf = StandardScaler()\n",
    "    X_train_lf = sc_lf.fit_transform(X_train_lf)\n",
    "    X_test_lf = sc_lf.transform(X_test_lf)\n",
    "\n",
    "    model_lf = model_gen(**model_args, input_shape=X_train_lf.shape[1:])\n",
    "    model_lf.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\",\n",
    "                     metrics=[\"accuracy\", \"binary_accuracy\",\n",
    "                              tfk.metrics.AUC(), tfk.metrics.Precision(), tfk.metrics.Recall()])\n",
    "\n",
    "    hist_lf = model_lf.fit(x=X_train_lf, y=y_train_lf, batch_size=24, epochs=3, validation_split=0.15)\n",
    "\n",
    "    eval_lf = model_lf.evaluate(X_test_lf, y_test_lf)\n",
    "    print(\"Leakage-free holdout accuracy:\", eval_lf[1])\n",
    "\n",
    "    # Holdout confusion matrix and report\n",
    "    y_hat_lf = model_lf.predict(X_test_lf)\n",
    "    y_hat_lf_bin = (y_hat_lf.T[0] >= 0.5).astype(int)\n",
    "\n",
    "    cm_lf = confusion_matrix(y_test_lf, y_hat_lf_bin)\n",
    "    print(\"\n",
    "Confusion Matrix (Leakage-Free Holdout):\n",
    "\", cm_lf)\n",
    "    print(\"\n",
    "Classification Report (Leakage-Free Holdout):\n",
    "\", classification_report(y_test_lf, y_hat_lf_bin, target_names=['No Alarm', 'Alarm']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation (Leakage-Free NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "lf_nn_accuracy_scores = []\n",
    "    lf_nn_auc_scores = []\n",
    "    lf_nn_precision_scores = []\n",
    "    lf_nn_recall_scores = []\n",
    "    lf_nn_loss_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(lf_df)):\n",
    "        train_df = lf_df.iloc[train_index]\n",
    "        val_df = lf_df.iloc[val_index]\n",
    "\n",
    "        # Train-only outlier bounds\n",
    "        lower, upper = lf_outlier_bounds(train_df, lf_features, multiplier=2.0)\n",
    "        train_df = lf_filter_outliers(train_df, lf_features, lower, upper)\n",
    "        val_df = lf_filter_outliers(val_df, lf_features, lower, upper)\n",
    "\n",
    "        X_train = train_df[lf_features].values\n",
    "        y_train = train_df[\"Fire Alarm\"].values\n",
    "        X_val = val_df[lf_features].values\n",
    "        y_val = val_df[\"Fire Alarm\"].values\n",
    "\n",
    "        sc_fold = StandardScaler()\n",
    "        X_train = sc_fold.fit_transform(X_train)\n",
    "        X_val = sc_fold.transform(X_val)\n",
    "\n",
    "        model_fold = model_gen(**model_args, input_shape=X_train.shape[1:])\n",
    "        model_fold.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\",\n",
    "                           metrics=[\"accuracy\", \"binary_accuracy\",\n",
    "                                    tfk.metrics.AUC(), tfk.metrics.Precision(), tfk.metrics.Recall()])\n",
    "\n",
    "        model_fold.fit(x=X_train, y=y_train, batch_size=24, epochs=3, verbose=0)\n",
    "        eval_metrics = model_fold.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "        lf_nn_loss_scores.append(eval_metrics[0])\n",
    "        lf_nn_accuracy_scores.append(eval_metrics[1])\n",
    "        lf_nn_auc_scores.append(eval_metrics[3])\n",
    "        lf_nn_precision_scores.append(eval_metrics[4])\n",
    "        lf_nn_recall_scores.append(eval_metrics[5])\n",
    "\n",
    "    print(\"\n",
    "Leakage-free NN K-fold summary:\")\n",
    "    print(\"Accuracy:  {:.4f} (+/- {:.4f})\".format(np.mean(lf_nn_accuracy_scores), np.std(lf_nn_accuracy_scores)))\n",
    "    print(\"AUC:       {:.4f} (+/- {:.4f})\".format(np.mean(lf_nn_auc_scores), np.std(lf_nn_auc_scores)))\n",
    "    print(\"Precision: {:.4f} (+/- {:.4f})\".format(np.mean(lf_nn_precision_scores), np.std(lf_nn_precision_scores)))\n",
    "    print(\"Recall:    {:.4f} (+/- {:.4f})\".format(np.mean(lf_nn_recall_scores), np.std(lf_nn_recall_scores)))\n",
    "    print(\"Loss:      {:.4f} (+/- {:.4f})\".format(np.mean(lf_nn_loss_scores), np.std(lf_nn_loss_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation (Leakage-Free SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "lf_svm_accuracy_scores = []\n",
    "    lf_svm_precision_scores = []\n",
    "    lf_svm_recall_scores = []\n",
    "    lf_svm_f1_scores = []\n",
    "    lf_all_y_true = []\n",
    "    lf_all_y_pred = []\n",
    "    lf_all_y_score = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(lf_df)):\n",
    "        train_df = lf_df.iloc[train_index]\n",
    "        val_df = lf_df.iloc[val_index]\n",
    "\n",
    "        # Train-only outlier bounds\n",
    "        lower, upper = lf_outlier_bounds(train_df, lf_features, multiplier=2.0)\n",
    "        train_df = lf_filter_outliers(train_df, lf_features, lower, upper)\n",
    "        val_df = lf_filter_outliers(val_df, lf_features, lower, upper)\n",
    "\n",
    "        X_train = train_df[lf_features].values\n",
    "        y_train = train_df[\"Fire Alarm\"].values\n",
    "        X_val = val_df[lf_features].values\n",
    "        y_val = val_df[\"Fire Alarm\"].values\n",
    "\n",
    "        sc_fold = StandardScaler()\n",
    "        X_train = sc_fold.fit_transform(X_train)\n",
    "        X_val = sc_fold.transform(X_val)\n",
    "\n",
    "        svm_model = SVC(random_state=42, C=0.5)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = svm_model.predict(X_val)\n",
    "        y_score = svm_model.decision_function(X_val)\n",
    "\n",
    "        report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        lf_svm_accuracy_scores.append(report['accuracy'])\n",
    "        lf_svm_precision_scores.append(report['1']['precision'])\n",
    "        lf_svm_recall_scores.append(report['1']['recall'])\n",
    "        lf_svm_f1_scores.append(report['1']['f1-score'])\n",
    "\n",
    "        lf_all_y_true.extend(y_val)\n",
    "        lf_all_y_pred.extend(y_pred)\n",
    "        lf_all_y_score.extend(y_score)\n",
    "\n",
    "    print(\"\n",
    "Leakage-free SVM K-fold summary:\")\n",
    "    print(\"Accuracy:  {:.4f} (+/- {:.4f})\".format(np.mean(lf_svm_accuracy_scores), np.std(lf_svm_accuracy_scores)))\n",
    "    print(\"Precision: {:.4f} (+/- {:.4f})\".format(np.mean(lf_svm_precision_scores), np.std(lf_svm_precision_scores)))\n",
    "    print(\"Recall:    {:.4f} (+/- {:.4f})\".format(np.mean(lf_svm_recall_scores), np.std(lf_svm_recall_scores)))\n",
    "    print(\"F1:        {:.4f} (+/- {:.4f})\".format(np.mean(lf_svm_f1_scores), np.std(lf_svm_f1_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage-Free Comparison Table\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "lf_nn_precision = float(np.mean(lf_nn_precision_scores))\n",
    "lf_nn_recall = float(np.mean(lf_nn_recall_scores))\n",
    "lf_nn_f1 = (2 * lf_nn_precision * lf_nn_recall / (lf_nn_precision + lf_nn_recall)) if (lf_nn_precision + lf_nn_recall) > 0 else np.nan\n",
    "\n",
    "lf_nn_summary = {\n",
    "    \"Accuracy\": float(np.mean(lf_nn_accuracy_scores)),\n",
    "    \"Precision\": lf_nn_precision,\n",
    "    \"Recall\": lf_nn_recall,\n",
    "    \"AUC\": float(np.mean(lf_nn_auc_scores)),\n",
    "    \"F1\": lf_nn_f1,\n",
    "    \"Loss\": float(np.mean(lf_nn_loss_scores)),\n",
    "}\n",
    "\n",
    "lf_svm_summary = {\n",
    "    \"Accuracy\": float(np.mean(lf_svm_accuracy_scores)),\n",
    "    \"Precision\": float(np.mean(lf_svm_precision_scores)),\n",
    "    \"Recall\": float(np.mean(lf_svm_recall_scores)),\n",
    "    \"F1\": float(np.mean(lf_svm_f1_scores)),\n",
    "}\n",
    "\n",
    "leakage_free_comparison = pd.DataFrame([\n",
    "    {\"Model\": \"Neural Network\", **lf_nn_summary},\n",
    "    {\"Model\": \"SVM\", **lf_svm_summary, \"AUC\": np.nan, \"Loss\": np.nan},\n",
    "], columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"AUC\", \"F1\", \"Loss\"])\n",
    "\n",
    "leakage_free_comparison\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03e334115a4d468ba8b25bfc890c57d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4247cfe5cf5948dd8102b88cda0dddd0",
      "placeholder": "​",
      "style": "IPY_MODEL_e04695933e9f4cfdb6424dcd28e064fc",
      "value": "100%"
     }
    },
    "0a1aa4b1538a48559a2c96e98f38eed5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5220e60c8bb041609c209e6e26d9d67d",
      "placeholder": "​",
      "style": "IPY_MODEL_2581111a76a94fcaa8192d672db1ebf1",
      "value": " 200/200 [02:15&lt;00:00,  1.25it/s]"
     }
    },
    "234f7feb7e6043c0baa78c9c2c9116c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d806b0afc2a944b9af538875c72b7e98",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a92a5441787b4136b0d4ac49d0245fc8",
      "value": 200
     }
    },
    "2581111a76a94fcaa8192d672db1ebf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4247cfe5cf5948dd8102b88cda0dddd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5220e60c8bb041609c209e6e26d9d67d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a92a5441787b4136b0d4ac49d0245fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6dd7ec8139648598ff619cf1f3ff6d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03e334115a4d468ba8b25bfc890c57d2",
       "IPY_MODEL_234f7feb7e6043c0baa78c9c2c9116c2",
       "IPY_MODEL_0a1aa4b1538a48559a2c96e98f38eed5"
      ],
      "layout": "IPY_MODEL_ced00cc34a94477eb50059a73fa5b315"
     }
    },
    "ced00cc34a94477eb50059a73fa5b315": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d806b0afc2a944b9af538875c72b7e98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e04695933e9f4cfdb6424dcd28e064fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}